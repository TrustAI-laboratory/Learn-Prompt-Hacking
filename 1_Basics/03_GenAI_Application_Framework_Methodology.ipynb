{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TrustAI-laboratory/Learn-Prompt-Hacking/blob/main/1_Basics/03_GenAI_Application_Framework_Methodology.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is GenAI Application Framework Methodology"
      ],
      "metadata": {
        "id": "12CMdisbEvs-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Prompting Method of Problem Solving with Generative AI is a framework for problem solving in the Gen AI space. It helps you decide whether GenAI is the right solution, how to apply prompt engineering, what tools to select, and more.\n",
        "\n",
        "We will walk through each of the five steps, then provide a case study using this method.\n"
      ],
      "metadata": {
        "id": "7qmA19IREzFp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Five Steps"
      ],
      "metadata": {
        "id": "l6VenUGQDmcv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1、State your problem\n",
        "\n",
        "The first step in is to state your problem. This involves clearly articulating the issue you are facing, without jumping to potential solutions.\n",
        "\n",
        "For instance, \"Our customers have queries about our product's features that need to be addressed, since we are missing out on potential business\".\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XlBAMGo_g9gx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2、Examine relevant information\n",
        "\n",
        "After stating your problem, the next step is to examine relevant information.\n",
        "\n",
        "This could include researching similar problems and their solutions, studying the context of your problem, or analyzing data related to your problem.\n",
        "\n",
        "It also includes finding relevant prompts and GenAI tools(such as LangChain, PromptAppGPT, Promptify, PromptFlow).\n",
        "\n",
        "This step is crucial in understanding the nuances of your problem and identifying potential approaches to solve it. At this point, you should know if GenAI is a good fit for your problem.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CKz8X08RhJlf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3、Propose a solution\n",
        "\n",
        "Once you've examined the relevant information, you should have a clearer idea of how to address your problem. Now it's time to propose a solution.\n",
        "\n",
        "This could be a prompt, a new tool, or a new way of using a current tool. The solution should be directly linked to the problem you've stated and the information you've examined."
      ],
      "metadata": {
        "id": "nrj5bu0dh0qE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4、Adjust the solution\n",
        "\n",
        "Once you've picked a solution, which could be a prompt or a tool, the next step is to adjust it based on feedback and testing.\n",
        "\n",
        "This could involve setting up tests to see how users interact with the prompt, getting feedback from users, or making adjustments based on your own intuition and expertise. This is where prompt engineering comes in!"
      ],
      "metadata": {
        "id": "dmEuQszkiBne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5、Launch your solution\n",
        "\n",
        "The final step is to launch your solution. This could involve integrating it into your product, publishing it on a platform, or simply starting to use it in your interactions with users.\n",
        "\n",
        "The Prompting Method is a cycle, not a linear process. After launching your solution, you should continue to monitor its performance and make adjustments as needed. You can use the acronym SEPAL to remember these steps!"
      ],
      "metadata": {
        "id": "yL3OtjAliM9a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Case Study: Using the Learn Prompting Method to Create a Hat Information Bot"
      ],
      "metadata": {
        "id": "TrEaBuhmj-RG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up ChatGPT"
      ],
      "metadata": {
        "id": "6li-fZxVklvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# we'll use these to read in some data from Colab\n",
        "!pip install openai\n",
        "from IPython.display import display, Markdown\n",
        "from google.colab import userdata\n",
        "import openai\n",
        "import os\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "# Set up your OpenAI API key\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "# Define function for printing long strings as markdown\n",
        "md_print = lambda text: display(Markdown(text))"
      ],
      "metadata": {
        "id": "ZnrMqH-7kxQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a Chatbot"
      ],
      "metadata": {
        "id": "_UP-Ausvk31X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a chatbot class\n",
        "\n",
        "class ChatBot:\n",
        "    def __init__(self):\n",
        "        # List to keep track of conversation history\n",
        "        self.context = []\n",
        "\n",
        "    def new_message(self, prompt):\n",
        "        # Append user prompt to chatbot context\n",
        "        self.context.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "        # Create assistant response\n",
        "        completion = openai.chat.completions.create(\n",
        "          model=\"gpt-3.5-turbo\",\n",
        "          messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "\n",
        "        # Parse assistant response\n",
        "        chat_response = completion.choices[0].message.content\n",
        "\n",
        "        # Add assistant response to context\n",
        "        self.context.append({\"role\": \"assistant\", \"content\": chat_response})\n",
        "\n",
        "        # Print out conversation\n",
        "        for message in self.context:\n",
        "            if message[\"role\"] == \"user\":\n",
        "                md_print(f'User: {message[\"content\"]}')\n",
        "            else:\n",
        "                md_print(f'GPT: {message[\"content\"]}')"
      ],
      "metadata": {
        "id": "QiSKxV_HlBkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Analysis"
      ],
      "metadata": {
        "id": "42OSp4-Hlc_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at a case study of how the Learn Prompting Method could be used to create a chatbot from scratch. In this case, we have a collection of user questions about hats.\n",
        "\n",
        "1. **State your problem**: We have a large volume of user queries about different types of hats, their history, and how to wear them. We need to do something about this because we are losing potential business.\n",
        "\n",
        "2. **Examine relevant information**: We analyze the user queries we have collected. We notice that the most common questions are about the history of specific types of hats, how to wear them properly, and how to care for them. We also look at existing chatbots, examining their context length, pricing, and speed, and GenAI tools that could potentially help us address our problem.\n",
        "\n",
        "3. **Propose a solution**: Based on our analysis, we decide to create a chatbot using ChatGPT that can answer these three types of questions. We draft an initial prompt:"
      ],
      "metadata": {
        "id": "J0yQZhMFkDvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create chatbot instance\n",
        "chatbot1 = ChatBot()\n",
        "# Prompt\n",
        "guidance_prompt =\"\"\"\n",
        "You are a knowledgeable hat historian who has studied the history, styles, and proper ways to wear various types of hats. A user asks you a question about hats.\n",
        "Respond to their query in a helpful and informative manner: {USER_INPUT}\n",
        "\"\"\"\n",
        "\n",
        "# the {USER_INPUT} will be replaced by real user input.\n",
        "guidance_prompt.format(USER_INPUT=\"what is price of the hat?\")\n",
        "\n",
        "\n",
        "chatbot1.new_message(guidance_prompt)"
      ],
      "metadata": {
        "id": "cJC_C8r5loFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Adjust the solution**: We test our initial prompts with a small group of users and collect their feedback. Based on their feedback, we realize that our prompts need to be more engaging and less formal.\n",
        "\n",
        "We adjust our prompts accordingly:"
      ],
      "metadata": {
        "id": "KfZfdfN0nLTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt\n",
        "guidance_prompt =\"\"\"\n",
        "You are a hat enthusiast with a wealth of knowledge about the history, styles, and etiquette of wearing various types of hats. A user is curious about hats and asks you a question. Respond to their query in a friendly and informative manner.\n",
        "Respond to their query in a helpful and informative manner: {USER_INPUT}\n",
        "\"\"\"\n",
        "\n",
        "# the {USER_INPUT} will be replaced by real user input.\n",
        "guidance_prompt.format(USER_INPUT=\"what is price of the hat?\")\n",
        "\n",
        "\n",
        "chatbot1.new_message(guidance_prompt)"
      ],
      "metadata": {
        "id": "WonP2xs9nRsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We do even more user testing and realize that we need to segment our market:\n",
        "* people interested hat history prefer the more formal approach,\n",
        "* while those interested in style and wearing the hat would prefer a more informal bot.\n",
        "\n",
        "We develop an initial routing prompt that decides which type of user they are based on their question:\n"
      ],
      "metadata": {
        "id": "WztnvzIiniLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt\n",
        "intension_input =\"\"\"\n",
        "You are an AI that understands the nuances of hat-related queries.\n",
        "Based on the user's question, determine if they are more interested in the formal history of hats or the informal style and wearing of hats.\n",
        "Respond with 'Formal' for history-related queries and 'Informal' for style and wearing-related queries.\"\n",
        "The question from user is: {USER_INPUT}\n",
        "\"\"\"\n",
        "\n",
        "# the {USER_INPUT} will be replaced by real user input.\n",
        "intension_input.format(USER_INPUT=\"what is price of the hat?\")\n",
        "\n",
        "\n",
        "chatbot1.new_message(intension_input)"
      ],
      "metadata": {
        "id": "Jj9V4cC5nsg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use a tool like Langchain, Voiceflow, or Dust to connect the routing prompt to the other two."
      ],
      "metadata": {
        "id": "INvODNH3oPWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **Launch your solution**: We launch the chatbot on our website. We continue to monitor user interactions with the bot and make further adjustments as needed."
      ],
      "metadata": {
        "id": "FxOR35NnoSTD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "By following the GenAI Application Framework Methodology, we were able to create a chatbot that effectively answers user queries about hats.\n",
        "\n",
        "This process highlights the importance of understanding user needs, testing and adjusting solutions, and continuously improving based on user feedback."
      ],
      "metadata": {
        "id": "pnS0rUjCoYC4"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}