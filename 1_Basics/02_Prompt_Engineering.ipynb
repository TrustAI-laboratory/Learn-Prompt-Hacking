{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TrustAI-laboratory/Learn-Prompt-Hacking/blob/main/1_Basics/02_Prompt_Engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up ChatGPT"
      ],
      "metadata": {
        "id": "12CMdisbEvs-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get started with ChatGPT, follow these steps:\n",
        "\n",
        "* Navigate to http://chat.openai.com\n",
        "* It should ask you to make an account. Go ahead and do so.\n",
        "* Log in with this account\n",
        "* Navigate to https://platform.openai.com/api-keys and creata a new secret key."
      ],
      "metadata": {
        "id": "7qmA19IREzFp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config"
      ],
      "metadata": {
        "id": "l6VenUGQDmcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# we'll use these to read in some data from Colab\n",
        "!pip install openai\n",
        "from IPython.display import display, Markdown\n",
        "from google.colab import userdata\n",
        "import openai\n",
        "import os\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "5KG_WfJmW-l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up your OpenAI API key\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "# Define function for printing long strings as markdown\n",
        "md_print = lambda text: display(Markdown(text))"
      ],
      "metadata": {
        "id": "KXFl7LWPEXc0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding AI Minds\n",
        "\n",
        "Just like all Machine Learning algorithms LLMs have adjustable hyperparameters. Some of the most commonly utilized include:\n",
        "\n",
        "* Temperature: A hyperparameter that influences the randomness of LLM output. A high temperature produces unpredictable and creative results, while a low temperature generates common and conservative output.\n",
        "\n",
        "* Top p: A hyperparameter that sets a probability threshold to select the most likely tokens for LLM output. By considering the top tokens whose cumulative probability exceeds the threshold, this method can create more diverse output. For example, setting top p to 0.9 only randomly samples from the most probable words that make up 90% of the probability mass. A high value means less candidates a low value means more candidates.\n",
        "\n",
        "* Frequency penalty: A penalty term applied to the generation process of a language model to avoid repeating words or phrases excessively. By adding a frequency penalty, the model is encouraged to generate text that is more diverse and avoids repetitive output.\n",
        "\n",
        "* Presence penalty: Another penalty term that discourages the model from generating specific words or phrases. By assigning a high penalty value to certain words or phrases, the model is less likely to use them in the generated text. This can be useful when generating text that needs to avoid specific words or phrases, for example, in sensitive or restricted domains.\n",
        "\n",
        "By understanding the relationship between these hyperparameter values and the model outputs practitioners can optimize their results by utilizing a combintation that works well with their given task and prompt set."
      ],
      "metadata": {
        "id": "hT7J7qIfX1bw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is Prompting?"
      ],
      "metadata": {
        "id": "2Mu1-wxoEnbU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Humans can instruct AIs to perform tasks. Using a prompt to instruct an AI to do a task is called prompting.\n",
        "\n",
        "We will explore prompting with ChatGPT, a very popular Large Language Model, that can understand and write text. It was developed by OpenAI, and is currently the easiest GenAI to work with."
      ],
      "metadata": {
        "id": "lNAHqHlsEqUw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNzHBFzfhfXx"
      },
      "source": [
        "# Prompting With ChatGPT"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obviously the OpenAI models are not the only LLM out there, but the easy access via the API and general model quality make it a good choice to use for showcasing prompting techniques throughout this course.\n",
        "\n",
        "First let's create a function for creating text via prompts using the OpenAI API:"
      ],
      "metadata": {
        "id": "cw9ttA8dxLM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Call ChatGPT API with prompt\n",
        "def call_GPT(prompt):\n",
        "    completion = openai.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "\n",
        "    # Parse results and print them out\n",
        "    chat_response = completion.choices[0].message.content\n",
        "    md_print(f'User: {prompt}')\n",
        "    md_print(f'GPT: {chat_response}')"
      ],
      "metadata": {
        "id": "SudBdjsXGJkH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us test some prompts on ChatGPT."
      ],
      "metadata": {
        "id": "W6-XbY2YGWO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define\n",
        "call_GPT(prompt=\"Write an essay explaining what AI is.\")"
      ],
      "metadata": {
        "id": "yrIdRvFDGc8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The process of instructing an AI to do a task through natural language is called prompting. We tell the AI what to do and is does it!\n",
        "\n",
        "Prompts can be as simple as an insturction or question or as complex as huge chunks of text."
      ],
      "metadata": {
        "id": "iRAorUveyHhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarization prompt\n",
        "\n",
        "summarize_prompt=\"\"\"\n",
        "It is very rare for snow to fall in the U.S. state of Florida, especially in the central and southern portions of the state. With the exception of the far northern areas of the state, most of the major cities in Florida have never recorded measurable snowfall, though trace amounts have been recorded, or flurries in the air observed few times each century. According to the National Weather Service, in the Florida Keys and Key West there is no known occurrence of snow flurries since the European colonization of the region more than 300 years ago. In Miami, Fort Lauderdale, and Palm Beach there has been only one known report of snow flurries observed in the air in more than 200 years; this occurred in January 1977. In any event, Miami, Fort Lauderdale, and Palm Beach have not seen snow flurries before or since this 1977 event.\n",
        "\n",
        "Summarize this paragraph in a single sentence:\n",
        "\"\"\"\n",
        "\n",
        "call_GPT(summarize_prompt)"
      ],
      "metadata": {
        "id": "1JgGZL6sIGlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instruction Prompting\n"
      ],
      "metadata": {
        "id": "COfQkpvXIguv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now cover our first prompting technique, instruction prompting. We can instruct Gen AIs to do much more complex tasks.\n",
        "\n",
        "Let's go ahead and have the AI follow some more complicated instructions:"
      ],
      "metadata": {
        "id": "gnSVWJTGIrsP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1、Name Parsing Instructions\n",
        "\n"
      ],
      "metadata": {
        "id": "N81qHwVaJhTi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A common problem when collecting name data is that different people format their names differently. Some might have Mrs. or Jr.. Additionally, the first and last name could be out of order. In the past, cleaning data like this has been a boring, manual task. Now, we can fully automate it with a simple prompt."
      ],
      "metadata": {
        "id": "4X0eMuUWKAjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instruction_prompt_example1 =\"\"\"\n",
        "A user has input their first and last name into a form. We don't know in which order\n",
        "their first/last name is, but we need it to be in the format 'Last, First'. Convert the following:\n",
        "\n",
        "john doe\n",
        "\"\"\"\n",
        "\n",
        "call_GPT(instruction_prompt_example1)"
      ],
      "metadata": {
        "id": "IBWcjK0AIkEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2、Personally Identifiable Information Removal Instructions"
      ],
      "metadata": {
        "id": "PrWWhMt9KGNd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PII removal is another relevant task. Before releasing private documents, corporations or governments may manually redact information from documents. Gen AI can be used to remove PII automatically, removing the need for intensive human effort"
      ],
      "metadata": {
        "id": "612wyzn2KKeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instruction_prompt_example2 =\"\"\"\n",
        "Read the following sales email. Remove any personally identifiable information (PII),\n",
        "and replace it with the appropriate placeholder. For example, replace the name \"John Doe\"\n",
        "with \"[NAME]\".\n",
        "\n",
        "Hi John,\n",
        "\n",
        "I'm writing to you because I noticed you recently purchased a new car. I'm a salesperson\n",
        "at a local dealership (Cheap Dealz), and I wanted to let you know that we have a great deal on a new\n",
        "car. If you're interested, please let me know.\n",
        "\n",
        "Thanks,\n",
        "\n",
        "Jimmy Smith\n",
        "\n",
        "Phone: 410-805-2345\n",
        "Email: jimmysmith@cheapdealz.com\n",
        "\"\"\"\n",
        "\n",
        "call_GPT(instruction_prompt_example2)"
      ],
      "metadata": {
        "id": "OQQs6Vl-I0gP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3、Essay Evaluation and Feedback Instructions"
      ],
      "metadata": {
        "id": "zk-v3I4gJpe4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gen AI can be utilized to evaluate and provide feedback on essays based on a complex set of criteria. This includes elements such as grammar, clarity, coherence, and argument quality."
      ],
      "metadata": {
        "id": "exUAjVTPJz-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instruction_prompt_example3 =\"\"\"\n",
        "Read the following excerpt from an essay and provide feedback based on the following criteria: grammar, clarity, coherence, argument quality, and use of evidence. Provide a score from 1-10 for each attribute, along with reasoning for your score.\n",
        "\n",
        "\"Despite the popular belief, there's no solid evidence supporting the idea that video games lead to violent behavior. Research on the topic is often contradictory and inconclusive. Some studies found a correlation, but correlation don't imply causation. So, it's premature to blame video games for violence in society.\"\n",
        "\"\"\"\n",
        "\n",
        "call_GPT(instruction_prompt_example3)"
      ],
      "metadata": {
        "id": "GvevJhvYK6XT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Role Prompting"
      ],
      "metadata": {
        "id": "469gHjV_LPBT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assigning roles to the LLM, or role prompting, is a technique that can be used to control the style of AI generated text. It can also improve the AI's accuracy when solving math problems.\n",
        "\n",
        "Implementing role prompting is as simple as instructing the AI to \"embody a food critic\" or to \"act like a detective\".\n",
        "\n",
        "Role prompting is a widely used technique."
      ],
      "metadata": {
        "id": "ax5f1hb1LY5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "role_prompt_example4 =\"\"\"\n",
        "You are a brilliant mathematician who can solve any problem in the world.\n",
        "Attempt to solve the following problem:\n",
        "\n",
        "What is (100*100)/(400*56)?\n",
        "\"\"\"\n",
        "\n",
        "call_GPT(role_prompt_example4)"
      ],
      "metadata": {
        "id": "t_Y3rBkKLX9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Few-Shot Prompting"
      ],
      "metadata": {
        "id": "LSThEYO0QNRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another prompting technique is Few-Shot Prompting which includes showing the model a few examples (called shots) of what you want it to do.\n",
        "\n",
        "Variants of this technique include Zero-shot prompting (where no examples are given) and One-shot prompting (where one example is given).\n",
        "\n",
        "The way you strcture the examples is important, they should be consistent. The distribution of your examples should be relatively even.\n"
      ],
      "metadata": {
        "id": "qItWhR0qQRdC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1、Structure Output\n",
        "\n",
        "A key use case for few-shot prompting is when you need the output to be structured in a specific way that is difficult to describe to the model. To understand this, let's consider a relevant example: say you are conducting an economic analysis and need to compile the names and occupations of well known citizens in towns nearby by analyzing local newspaper articles.\n",
        "\n",
        "You would like the model to read each article and output a list of names and occupations in First Last [OCCUPATION] format. In order to get the model to do this, you can show it a few examples."
      ],
      "metadata": {
        "id": "UqJgXnxYQ2LO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "role_prompt_example5 =\"\"\"\n",
        "In the bustling town of Emerald Hills, a diverse group of individuals made their mark. Sarah Martinez, a dedicated nurse, was known for her compassionate care at the local hospital. David Thompson, an innovative software engineer, worked tirelessly on groundbreaking projects that would revolutionize the tech industry. Meanwhile, Emily Nakamura, a talented artist and muralist, painted vibrant and thought-provoking pieces that adorned the walls of buildings and galleries alike. Lastly, Michael O'Connell, an ambitious entrepreneur, opened a unique, eco-friendly cafe that quickly became the town's favorite meeting spot. Each of these individuals contributed to the rich tapestry of the Emerald Hills community.\n",
        "1. Sarah Martinez [NURSE]\n",
        "2. David Thompson [SOFTWARE ENGINEER]\n",
        "3. Emily Nakamura [ARTIST]\n",
        "4. Michael O'Connell [ENTREPRENEUR]\n",
        "\n",
        "At the heart of the town, Chef Oliver Hamilton has transformed the culinary scene with his farm-to-table restaurant, Green Plate. Oliver's dedication to sourcing local, organic ingredients has earned the establishment rave reviews from food critics and locals alike.\n",
        "\n",
        "Just down the street, you'll find the Riverside Grove Library, where head librarian Elizabeth Chen has worked diligently to create a welcoming and inclusive space for all. Her efforts to expand the library's offerings and establish reading programs for children have had a significant impact on the town's literacy rates.\n",
        "\n",
        "As you stroll through the charming town square, you'll be captivated by the beautiful murals adorning the walls. These masterpieces are the work of renowned artist, Isabella Torres, whose talent for capturing the essence of Riverside Grove has brought the town to life.\n",
        "\n",
        "Riverside Grove's athletic achievements are also worth noting, thanks to former Olympic swimmer-turned-coach, Marcus Jenkins. Marcus has used his experience and passion to train the town's youth, leading the Riverside Grove Swim Team to several regional championships.\n",
        "1. Oliver Hamilton [CHEF]\n",
        "2. Elizabeth Chen [LIBRARIAN]\n",
        "3. Isabella Torres [ARTIST]\n",
        "4. Marcus Jenkins [COACH]\n",
        "\n",
        "Oak Valley, a charming small town, is home to a remarkable trio of individuals whose skills and dedication have left a lasting impact on the community.\n",
        "\n",
        "At the town's bustling farmer's market, you'll find Laura Simmons, a passionate organic farmer known for her delicious and sustainably grown produce. Her dedication to promoting healthy eating has inspired the town to embrace a more eco-conscious lifestyle.\n",
        "\n",
        "In Oak Valley's community center, Kevin Alvarez, a skilled dance instructor, has brought the joy of movement to people of all ages. His inclusive dance classes have fostered a sense of unity and self-expression among residents, enriching the local arts scene.\n",
        "\n",
        "Lastly, Rachel O'Connor, a tireless volunteer, dedicates her time to various charitable initiatives. Her commitment to improving the lives of others has been instrumental in creating a strong sense of community within Oak Valley.\n",
        "\n",
        "Through their unique talents and unwavering dedication, Laura, Kevin, and Rachel have woven themselves into the fabric of Oak Valley, helping to create a vibrant and thriving small town.\n",
        "\"\"\"\n",
        "\n",
        "call_GPT(role_prompt_example5)"
      ],
      "metadata": {
        "id": "WDTnzUIQRMEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The word \"shot\" is synonymous with \"example\". Aside from few-shot prompting, there are two other types of shot prompting that exist. The only difference between these variants is how many examples you show the model."
      ],
      "metadata": {
        "id": "hKUKSDvgUoGq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2、Zero-shot prompting\n",
        "\n",
        "Zero-shot prompting prompting is the most basic form of prompting. It simply shows the model a prompt without examples and asks it to generate a response. As such, all of the instruction and role prompts that you have seen so far are zero-shot prompts."
      ],
      "metadata": {
        "id": "lfHlPsYyVCiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "role_prompt_example6 =\"\"\"\n",
        "Add 2+2:\n",
        "\"\"\"\n",
        "\n",
        "call_GPT(role_prompt_example6)"
      ],
      "metadata": {
        "id": "NkYZqL5rVFVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3、One-shot prompting\n",
        "\n",
        "One-shot prompting is when you show the model a single example."
      ],
      "metadata": {
        "id": "09GaETFdVN_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "role_prompt_example7 =\"\"\"\n",
        "Add 3+3: 6\n",
        "Add 2+2:\n",
        "\"\"\"\n",
        "\n",
        "call_GPT(role_prompt_example7)"
      ],
      "metadata": {
        "id": "DTLNkGIFVQwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combining Techniques"
      ],
      "metadata": {
        "id": "LJGLULehWXme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have now covered multiple types of prompts, as well as ways to combine them."
      ],
      "metadata": {
        "id": "P3k7lx5RWbMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A prompt including context, instructions, and multiple examples\n",
        "combined_prompt =\"\"\"\n",
        "Twitter is a social media platform where users can post short messages called \"tweets\".\n",
        "Tweets can be positive or negative, and we would like to be able to classify tweets as\n",
        "positive or negative. Here are some examples of positive and negative tweets. Make sure\n",
        "to classify the last tweet correctly.\n",
        "\n",
        "Q: Tweet: \"What a beautiful day!\"\n",
        "Is this tweet positive or negative?\n",
        "\n",
        "A: positive\n",
        "\n",
        "Q: Tweet: \"I hate this class\"\n",
        "Is this tweet positive or negative?\n",
        "\n",
        "A: negative\n",
        "\n",
        "Q: Tweet: \"I love pockets on jeans\"\n",
        "\n",
        "A:\n",
        "\"\"\"\n",
        "\n",
        "call_GPT(combined_prompt)"
      ],
      "metadata": {
        "id": "WTdyQAt1WdrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Formalizing Prompting"
      ],
      "metadata": {
        "id": "R_3qCV1jVyee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In more complex application development scenarios, you can combine the above-mentioned technologies in a certain order to guide LLM to complete the task according to your task intention.\n",
        "\n",
        "They are roughly:\n",
        "\n",
        "* A role\n",
        "* An instruction/task\n",
        "* A question\n",
        "* Context\n",
        "* Examples (few-shot)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rHEbl7SLV8ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complex prompt example 1\n",
        "# role, instruction, context\n",
        "complex_prompt_example1 =\"\"\"\n",
        "You are a doctor. Read this medical history and predict risks for the patient:\n",
        "\n",
        "January 1, 2000: Fractured right arm playing basketball. Treated with a cast.\n",
        "February 15, 2010: Diagnosed with hypertension. Prescribed lisinopril.\n",
        "September 10, 2015: Developed pneumonia. Treated with antibiotics and recovered fully.\n",
        "March 1, 2022: Sustained a concussion in a car accident. Admitted to the hospital and monitored for 24 hours.\n",
        "\"\"\"\n",
        "\n",
        "call_GPT(complex_prompt_example1)"
      ],
      "metadata": {
        "id": "TFyE2KLKWP3z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}