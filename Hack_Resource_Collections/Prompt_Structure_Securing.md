## üîê Secure Prompting
Repositories dedicated to securing prompts and mitigating vulnerabilities.

- üåü | [Valhall-ai/prompt-injection-mitigations](https://github.com/Valhall-ai/prompt-injection-mitigations) - Mitigation strategies for prompt injections.
- üî• | [cckuailong/awesome-gpt-security](https://github.com/cckuailong/awesome-gpt-security) - A curated list of GPT security best practices.
- [GPTGeeker/securityGPT](https://github.com/GPTGeeker/securityGPT) - Security-focused prompts for GPT models.
- [mykeln/GPTect](https://github.com/mykeln/GPTect) - GPT security protection techniques.
- [gavin-black-dsu/securePrompts](https://github.com/gavin-black-dsu/securePrompts) - Repository with secure GPT prompts.
- [zinccat/PromptSafe](https://github.com/zinccat/PromptSafe) - Ensuring safe prompts for GPT models.
- [BenderScript/PromptGuardian](https://github.com/BenderScript/PromptGuardian) - Guardian scripts for securing GPT prompts.
- [sinanw/llm-security-prompt-injection](https://github.com/sinanw/llm-security-prompt-injection) - Security-focused prompt injection repository.
