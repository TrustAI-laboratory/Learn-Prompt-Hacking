# Learn-Prompt-Hacking

This repository documents our progress on a prompt engineering and prompt hacking course, focused on 
* developing techniques.
* strategies for working with the latest generation of general-purpose Large Language Models (LLMs).
* the latest prompt hacking technology and mitigation

## Background
With the release of ChatGPT, LLMs have become increasingly mainstream, revolutionizing the way we interact with AI systems. Prior to ChatGPT, there were several notable advancements in NLP that have laid the foundation for this revolution, including the "Attention is All You Need" paper by Vaswani et. al., BERT, GPT-2, GPT-3, T5, RoBERTa, ELECTRA, and ALBERT. Although these advancements are highly important, they may not be widely known to the general public. The year 2023 marks a turning point in the mass adoption of these general-purpose models across various industries for generative tasks. As a Data Scientist, continuous learning is a key attribute, and staying on the cutting edge of LLM techniques is essential for providing optimally viable solutions in the era of AI-driven Natural Language Processing.

On the other hand, the rapid arrival of AI has also brought a large number of new attack surfaces and risks to the entire IT software ecosystem. Data scientists and developers also need to pay attention to LLM security issues.


## Course Objective
The primary goal of this course is:
* gain a deep understanding of prompt engineering techniques for effective interaction with LLMs. By mastering these strategies, I aim to improve my ability to develop innovative, effective, and efficient solutions using the power of natural language.
* gain a basic understanding of the risks faced by LLM applications and learn to how to mitigate or prevent the GenAI App risk.
